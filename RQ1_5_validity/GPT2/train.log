/root/miniconda3/envs/vulrepair/lib/python3.9/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0
04/04/2023 21:13:03 - WARNING - __main__ -   device: cpu, n_gpu: 2
Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<00:00, 40.6kB/s]
Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:06<00:00, 167kB/s]Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:06<00:00, 167kB/s]
Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:01<00:00, 241kB/s]Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:01<00:00, 241kB/s]
Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]Downloading pytorch_model.bin:   2%|▏         | 10.5M/548M [00:00<00:32, 16.6MB/s]Downloading pytorch_model.bin:   4%|▍         | 21.0M/548M [00:00<00:20, 25.8MB/s]Downloading pytorch_model.bin:   6%|▌         | 31.5M/548M [00:01<00:16, 31.6MB/s]Downloading pytorch_model.bin:   8%|▊         | 41.9M/548M [00:01<00:14, 35.6MB/s]Downloading pytorch_model.bin:  10%|▉         | 52.4M/548M [00:01<00:13, 36.7MB/s]Downloading pytorch_model.bin:  11%|█▏        | 62.9M/548M [00:01<00:12, 37.7MB/s]Downloading pytorch_model.bin:  13%|█▎        | 73.4M/548M [00:02<00:12, 39.4MB/s]Downloading pytorch_model.bin:  15%|█▌        | 83.9M/548M [00:02<00:13, 34.4MB/s]Downloading pytorch_model.bin:  17%|█▋        | 94.4M/548M [00:02<00:12, 36.1MB/s]Downloading pytorch_model.bin:  19%|█▉        | 105M/548M [00:03<00:11, 38.2MB/s] Downloading pytorch_model.bin:  21%|██        | 115M/548M [00:03<00:10, 39.8MB/s]Downloading pytorch_model.bin:  23%|██▎       | 126M/548M [00:03<00:10, 41.2MB/s]Downloading pytorch_model.bin:  25%|██▍       | 136M/548M [00:03<00:09, 42.2MB/s]Downloading pytorch_model.bin:  27%|██▋       | 147M/548M [00:03<00:09, 42.4MB/s]Downloading pytorch_model.bin:  29%|██▊       | 157M/548M [00:04<00:09, 43.1MB/s]Downloading pytorch_model.bin:  31%|███       | 168M/548M [00:04<00:08, 43.6MB/s]Downloading pytorch_model.bin:  33%|███▎      | 178M/548M [00:04<00:08, 43.7MB/s]Downloading pytorch_model.bin:  34%|███▍      | 189M/548M [00:04<00:08, 44.0MB/s]Downloading pytorch_model.bin:  36%|███▋      | 199M/548M [00:05<00:07, 44.0MB/s]Downloading pytorch_model.bin:  38%|███▊      | 210M/548M [00:05<00:07, 44.1MB/s]Downloading pytorch_model.bin:  40%|████      | 220M/548M [00:05<00:07, 44.3MB/s]Downloading pytorch_model.bin:  42%|████▏     | 231M/548M [00:05<00:07, 44.3MB/s]Downloading pytorch_model.bin:  44%|████▍     | 241M/548M [00:06<00:06, 44.4MB/s]Downloading pytorch_model.bin:  46%|████▌     | 252M/548M [00:06<00:06, 44.2MB/s]Downloading pytorch_model.bin:  48%|████▊     | 262M/548M [00:06<00:06, 44.3MB/s]Downloading pytorch_model.bin:  50%|████▉     | 273M/548M [00:06<00:06, 44.3MB/s]Downloading pytorch_model.bin:  52%|█████▏    | 283M/548M [00:07<00:05, 44.2MB/s]Downloading pytorch_model.bin:  54%|█████▎    | 294M/548M [00:07<00:05, 44.2MB/s]Downloading pytorch_model.bin:  55%|█████▌    | 304M/548M [00:07<00:05, 44.1MB/s]Downloading pytorch_model.bin:  57%|█████▋    | 315M/548M [00:07<00:05, 43.1MB/s]Downloading pytorch_model.bin:  59%|█████▉    | 325M/548M [00:08<00:05, 43.3MB/s]Downloading pytorch_model.bin:  61%|██████    | 336M/548M [00:08<00:04, 43.5MB/s]Downloading pytorch_model.bin:  63%|██████▎   | 346M/548M [00:08<00:04, 43.4MB/s]Downloading pytorch_model.bin:  65%|██████▌   | 357M/548M [00:08<00:04, 43.8MB/s]Downloading pytorch_model.bin:  67%|██████▋   | 367M/548M [00:08<00:04, 43.9MB/s]Downloading pytorch_model.bin:  69%|██████▉   | 377M/548M [00:09<00:03, 44.1MB/s]Downloading pytorch_model.bin:  71%|███████   | 388M/548M [00:09<00:03, 44.3MB/s]Downloading pytorch_model.bin:  73%|███████▎  | 398M/548M [00:09<00:03, 40.5MB/s]Downloading pytorch_model.bin:  75%|███████▍  | 409M/548M [00:09<00:03, 41.4MB/s]Downloading pytorch_model.bin:  77%|███████▋  | 419M/548M [00:10<00:03, 42.4MB/s]Downloading pytorch_model.bin:  78%|███████▊  | 430M/548M [00:10<00:02, 42.8MB/s]Downloading pytorch_model.bin:  80%|████████  | 440M/548M [00:10<00:02, 43.2MB/s]Downloading pytorch_model.bin:  82%|████████▏ | 451M/548M [00:10<00:02, 42.8MB/s]Downloading pytorch_model.bin:  84%|████████▍ | 461M/548M [00:11<00:02, 40.4MB/s]Downloading pytorch_model.bin:  86%|████████▌ | 472M/548M [00:11<00:01, 40.7MB/s]Downloading pytorch_model.bin:  88%|████████▊ | 482M/548M [00:11<00:01, 41.5MB/s]Downloading pytorch_model.bin:  90%|████████▉ | 493M/548M [00:11<00:01, 42.3MB/s]Downloading pytorch_model.bin:  92%|█████████▏| 503M/548M [00:12<00:01, 38.7MB/s]Downloading pytorch_model.bin:  94%|█████████▎| 514M/548M [00:12<00:01, 29.0MB/s]Downloading pytorch_model.bin:  96%|█████████▌| 524M/548M [00:13<00:00, 32.3MB/s]Downloading pytorch_model.bin:  98%|█████████▊| 535M/548M [00:13<00:00, 35.1MB/s]Downloading pytorch_model.bin:  99%|█████████▉| 545M/548M [00:13<00:00, 37.3MB/s]Downloading pytorch_model.bin: 100%|██████████| 548M/548M [00:13<00:00, 40.1MB/s]
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
04/04/2023 21:14:30 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../../data/big-vul_dataset/train.csv', output_dir='../results/saved_models', model_type='roberta', block_size=512, eval_data_file='../../data/big-vul_dataset/val.csv', test_data_file='../../data/big-vul_dataset/test.csv', model_name='gpt2.bin', model_name_or_path=None, config_name='', use_non_pretrained_model=False, tokenizer_name='', code_length=256, do_train=True, do_eval=False, do_test=True, evaluate_during_training=True, do_local_explanation=False, reasoning_method=None, train_batch_size=16, eval_batch_size=16, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=123456, epochs=10, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=2, device=device(type='cpu'))
